{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBaU6ebvmpKOv0EE9pRLoW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ObjectMatrix/neural-network/blob/main/nnwine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lgelnKJLAytD"
      },
      "outputs": [],
      "source": [
        "!pip install -q pandas numpy scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data source:\n",
        "https://archive.ics.uci.edu/dataset/109/wine\n",
        "\n",
        "example:  \n",
        "**Summary of the Tutorial**  \n",
        "The tutorial explains the basics of neural networks, focusing on the Multi-Layer Perceptron (MLP), a type of feedforward neural network. It uses SciKit-Learn’s MLPClassifier to classify wine cultivars (three classes) based on 13 chemical features. The process includes loading and exploring the dataset, preprocessing the data, splitting it into training and testing sets, training the neural network, making predictions, and evaluating the model’s performance. The example achieves high accuracy with minimal code, demonstrating the power and simplicity of SciKit-Learn for neural network tasks."
      ],
      "metadata": {
        "id": "9_rONiZFQVPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "1PDAK-NpNxVd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine = pd.read_csv('https://raw.githubusercontent.com/ObjectMatrix/neural-network/main/data/wine.data', names=[\n",
        "    \"Cultivar\", \"Alcohol\", \"Malic_Acid\", \"Ash\", \"Alcalinity_of_Ash\",\n",
        "    \"Magnesium\", \"Total_phenols\", \"Flavanoids\", \"Nonflavanoid_phenols\",\n",
        "    \"Proanthocyanins\", \"Color_intensity\", \"Hue\", \"OD280\", \"Proline\"\n",
        "])\n"
      ],
      "metadata": {
        "id": "P-tvBlXEOSGd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(wine.head())  # View the first few rows\n",
        "print(wine.describe())  # Summary statistics\n",
        "print(wine.shape)  # (178, 14) - 178 samples, 14 columns (13 features + 1 target)"
      ],
      "metadata": {
        "id": "x-8kCaPVOzt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the Data  \n",
        "Separate Features and Target: Split the data into input features (X) and the target variable (y):"
      ],
      "metadata": {
        "id": "iFzo4RSkRy89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = wine.drop('Cultivar', axis=1)  # Features (drop the target column)\n",
        "y = wine['Cultivar']  # Target (cultivar labels)"
      ],
      "metadata": {
        "id": "LYwnw6RrPAWU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Split into Training and Testing Sets: Use 70% of the data for training and 30% for testing:"
      ],
      "metadata": {
        "id": "l15imuzoRfEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "wRfOqUwQPAZ-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scale the Features: Neural networks perform better with normalized data. Use StandardScaler to standardize the features (mean=0, variance=1):"
      ],
      "metadata": {
        "id": "egz05Al7R8Nf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)  # Fit the scaler on training data only\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "emwOt1QiPAfQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build and Train the Neural Network   \n",
        "Create an MLPClassifier instance with three hidden layers (each with 13 neurons, matching the number of features) and a maximum of 500 iterations:"
      ],
      "metadata": {
        "id": "t29XD9m_R-eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(hidden_layer_sizes=(13, 13, 13), max_iter=500, random_state=42)"
      ],
      "metadata": {
        "id": "fJ9ZJ3DUPAjH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model on the scaled training data:"
      ],
      "metadata": {
        "id": "rPyM3iO1SLLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "LHUJ1r0VPOXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Predictions  \n",
        "Use the trained model to predict the wine cultivars for the test set:"
      ],
      "metadata": {
        "id": "s0YdIzmtSXEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = mlp.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "NU8sffdrPOcV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the Model\n",
        "Print a confusion matrix to see how predictions align with actual labels:"
      ],
      "metadata": {
        "id": "ewmL_HmnSu7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test, predictions))"
      ],
      "metadata": {
        "id": "r1FlAfvBSoLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print a classification report for precision, recall, and F1-score:"
      ],
      "metadata": {
        "id": "EbmJEdLQS6DW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "id": "fOqHq6SvS_Fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment and Explore   \n",
        "Try tweaking parameters like hidden_layer_sizes (e.g., (10, 10) or (20, 20, 20)), max_iter, or activation (default is 'relu') to see how they affect performance.\n",
        "Example:"
      ],
      "metadata": {
        "id": "4VAMSiLeTFFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(hidden_layer_sizes=(20, 20), max_iter=1000, activation='tanh')\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "predictions = mlp.predict(X_test_scaled)\n",
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "id": "26HZoaEaTMVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Takeaways   \n",
        "Neural Networks: The MLP consists of an input layer (13 features), hidden layers (processing units), and an output layer (3 classes).\n",
        "Preprocessing: Scaling is critical for MLP performance.\n",
        "Ease of Use: SciKit-Learn simplifies neural network implementation.\n",
        "Limitations: MLP weights and biases are hard to interpret, and SciKit-Learn isn’t optimized for GPUs (unlike TensorFlow)."
      ],
      "metadata": {
        "id": "OwdzvZd4TXx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Steps   \n",
        "Download the dataset and run the code in a Jupyter Notebook to see it in action.\n",
        "Explore other datasets (e.g., SciKit-Learn’s built-in load_breast_cancer) using the same workflow.\n",
        "Learn more about neural networks by experimenting with frameworks like TensorFlow for GPU support."
      ],
      "metadata": {
        "id": "ASSlx02nThcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "05AZeGPWSbwk"
      }
    }
  ]
}